model: openllama_peft
imagebind_ckpt_path: ""
vicuna_ckpt_path: ./ckpt/vicuna-13b-v1.5  # Should be modified to your own place
orig_delta_path: ""
delta_ckpt_path: ./ckpt/MultiResQFormer/pytorch_model_4_5001.pt

all_decode_info: [
  # ["audioimage", "image_input", "example_image.json"]
  # ["audio", "audio_input", "example_audio.json"]
  # ["audiovideoimage", "audiovideo_input", "example_video.json"]



  # # Level 1
  # ["audio",           "L1_LAQA", "/share/nlp/tuwenming/projects/HAVIB/data/levels/level_1/LAQA"],
  # ["audioimage",      "L1_LIQA", "/share/nlp/tuwenming/projects/HAVIB/data/levels/level_1/LIQA"],
  # ["audiovideoimage", "L1_LVQA", "/share/nlp/tuwenming/projects/HAVIB/data/levels/level_1/LVQA"],

  # # Level 2
  # ["audio",           "L2_MAIC", "/share/nlp/tuwenming/projects/HAVIB/data/levels/level_2/MAIC"],
  # ["audioimage",      "L2_MVIC", "/share/nlp/tuwenming/projects/HAVIB/data/levels/level_2/MVIC"],

  # # Level 3
  # ["audiovideoimage", "L3_AVH",  "/share/nlp/tuwenming/projects/HAVIB/data/levels/level_3/AVH"],
  ["audiovideoimage",      "L3_AVL",  "/share/nlp/tuwenming/projects/HAVIB/data/levels/level_3/AVL"],
  # ["audiovideoimage", "L3_AVM",  "/share/nlp/tuwenming/projects/HAVIB/data/levels/level_3/AVM"],
  # ["audiovideoimage",      "L3_AVR",  "/share/nlp/tuwenming/projects/HAVIB/data/levels/level_3/AVR"],
  # ["audiovideoimage", "L3_VAH",  "/share/nlp/tuwenming/projects/HAVIB/data/levels/level_3/VAH"],
  # ["audiovideoimage",      "L3_VAR",  "/share/nlp/tuwenming/projects/HAVIB/data/levels/level_3/VAR"],

  # # Level 4
  # ["audiovideoimage", "L4_AVC",  "/share/nlp/tuwenming/projects/HAVIB/data/levels/level_4/AVC"],
  ["audiovideoimage",      "L4_AVLG", "/share/nlp/tuwenming/projects/HAVIB/data/levels/level_4/AVLG"],
  # ["audiovideoimage", "L4_AVQA", "/share/nlp/tuwenming/projects/HAVIB/data/levels/level_4/AVQA"],

  # # Level 5
  ["audiovideoimage",      "L5_AVLG", "/share/nlp/tuwenming/projects/HAVIB/data/levels/level_5/AVLG"],
  # ["audiovideoimage", "L5_AVQA", "/share/nlp/tuwenming/projects/HAVIB/data/levels/level_5/AVQA"],
]

stage: 2y
max_tgt_len: 512 # 32000
yu_lora_r: 32 # 8
yu_lora_alpha: 32
yu_lora_dropout: 0.1
lora_target_modules: ["q_proj", "k_proj", "v_proj", "o_proj"] # ['q_proj', 'v_proj']
use_lora: "true"
qformer: "true"
use_whisper: "true"
use_blip: "true"
instructblip: "true"
proj_checkpoint: ""
num_video_query: 30
instructblip_video: "false"
video_window_size: 240
skip_vqformer: "false"
speech_qformer: "false"
early_align: "true"
cascaded: ""
causal: "false"
diversity_loss: "false"
causal_attention: "true" # "false"
groupsize: 10
alignmode: 2
pure_aud: False
num_speech_query: 1
second_per_frame: 0.333333
second_stride: 0.333333
sin_pos: False
use_beats: True # True
return_raw: True # True
n_pos: 120
flash_attn: False
batch_size: 1
infer_mode: 2
bilinear_pooling: False
# ext_groupsize: [1, 30]
low_groupsize: 1
# # high_groupsize: 20
ext_same_qformer: True
cache_dir: ./ckpt/pretrained_ckpt
